---
title: "An Analysis of Beer: ABV, IBU, and Distribution by State"
author: "Jules Stacy"
date: "January 15, 2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

https://youtu.be/4s90tmhPOvw

All code used will be compiled and displayed in the final document. Output for certain code chunks will be hidden using the following code:
#knitr::opts_chunk$set(eval = TRUE, echo = TRUE, results = "hide")

The following code loads the libraries and sets the theme for the document:
```{r libraries, eval = TRUE, echo = TRUE, message=FALSE, results = "hide"}
library(multcomp)
library(plotly)
library(class)
library(caret)
library(e1071)
library(ggplot2)
library(tidyverse)


theme_set(
  theme_minimal()
)
```

The following code imports the dataset, sets column names, and cleans spaces out of some of the state labels
```{r}
beer_df = read.csv("Beers.csv")
breweries_df = read.csv("Breweries.csv")

#data cleaning
colnames(breweries_df) <- c("Brewery_id", "Brewery", "City", "State")
breweries_df$State <- str_replace_all(breweries_df$State, " ", "")
```

The following code generates table 1 and figure 1.
```{r Problem 1}
tab_1 = table(breweries_df$State)
breweries_1 <- as.data.frame(tab_1)
names(breweries_1) <- c("State", "Count")
breweries_1 <- breweries_1[order(breweries_1$Count),]

fig_1 = ggplot(data=breweries_1, ) +
  geom_bar(mapping = aes(x=reorder(State, Count), y=Count, fill=State), stat="identity") +
    #labels
  labs(title = "Figure 1",
       subtitle = "Number of Breweries by State",
       caption = "Source: Breweries.csv \n Author: Jules Stacy",
       x = "States",
       y = "Count of Breweries")

```
```{r Table 1}
tx <- tab_1
tx[order(tx)]

```

Table 1 is a table showing the number of breweries in each state. This includes breweries with multiple locations throughout the state.

```{r Figure 1}
fig_1 + theme(legend.position = "none", axis.text.x = element_text(angle = 90, hjust = 1))
```

Figure one is a graphical representation of the same data. We can see that Colorado, California, and Michigan have the highest number of breweries, respectively.

The following code merges the provided csv's as requested.
```{r Problem 2, eval = TRUE, echo = TRUE, message=FALSE, results = "hide"}
knitr::opts_chunk$set(eval = TRUE, echo = TRUE, results = "hide")
#perform merge
mbeer_orig = merge(beer_df, breweries_df, by="Brewery_id")

#duplicate beers were found, cleaning
mbeer <- mbeer_orig %>% distinct(Name, ABV, IBU, Style, Ounces, .keep_all=TRUE)

#Data was cleaned so that duplicates were removed based on name, abv, ibu, and product size in ounces
```
```{r Tables 2 and 3}
head(mbeer, 6)
tail(mbeer, 6)
```

Above are Tables 2 and 3 (not shown); the first and last 6 rows from the merged data set, respectively.

```{r Problem 3}
```

Dealing with missing (or NA) values:
Analyses dealing solely with ABV can include beers with missing IBU values and vice versa. Analyses dealing with both ABV and IBU will not include any beers that have NA values for either of these variables.


The following code are custom functions to calculate the median and max values while filtering out NA values.
```{r Custom Functions, eval = TRUE, echo = TRUE, message=FALSE, results = "hide"}
median_exNA<-function(input) {
   median(input[which(!is.na(input))])
}

max_exNA<-function(input) {
   max(input[which(!is.na(input))])
}
```

The following code generates figure 2 and 3, which show median ABV and IBU by states.
```{r Problem 4}
abv_state <- aggregate(ABV ~ State, mbeer, median_exNA)
ibu_state <- aggregate(IBU ~ State, mbeer, median_exNA)
#NA values have been removed

#Plot: ABV by State
fig_2 = ggplot(data=abv_state, aes(x=reorder(State, ABV), y=ABV, fill=State)) +
  geom_bar(stat="identity") +
    #labels
  labs(title = "Figure 2",
       subtitle = "Median ABV by State",
       caption = "Source: Breweries.csv \n Author: Jules Stacy",
       x = "States",
       y = "Median ABV")

#Plot: IBU by State
fig_3 = ggplot(data=ibu_state, aes(x=reorder(State, IBU), y=IBU, fill=State)) +
  geom_bar(stat="identity") +
    #labels
  labs(title = "Figure 3",
       subtitle = "Median IBU by State",
       caption = "Source: Breweries.csv \n Author: Jules Stacy",
       x = "States",
       y = "Median IBU")
```

```{r Table 4: Median ABV by State}
abv_state <- abv_state[order(abv_state$ABV),]
head(abv_state, 6)
```

Table 4, (not shown), is the first six rows showing the median ABV by state.
```{r Table 5: Mean IBU by State}
ibu_state <- ibu_state[order(ibu_state$IBU),]
head(ibu_state, 6)

```


Table 5, (not shown), is the first six rows showing the median ABV by state.
```{r Figure 2}
fig_2 + theme(legend.position = "none", axis.text.x = element_text(angle = 90, hjust = 1))
```
Figure 2, above, shows the median ABV by state.

```{r Figure 3}
fig_3 + theme(legend.position = "none", axis.text.x = element_text(angle = 90, hjust = 1))
```
Figure 3, above, shows the median IBU by state.

```{r Problem 5}

abv_max <- aggregate(ABV ~ State, mbeer, max_exNA)
ibu_max <- aggregate(IBU ~ State, mbeer, max_exNA)
#NA values have been removed
```

Colorado has the beer with the highest ABV at 0.128.
Oregon has the most bitter beer with an IBU of 138.


The code below generates Figure 4, generates a datset without NA values, and calls the summary statistics for ABV. The data includes beers that have missing IBU values.
```{r Problem 6, eval = TRUE, echo = TRUE, message=FALSE, results = "hide"}
#Plot: ABV by State
fig_4 = ggplot(mbeer) +
  geom_density(aes(ABV), color="deeppink3") +
    #labels
  labs(title = "Figure 4",
       subtitle = "Distribution of ABV",
       caption = "Source: Breweries.csv \n Author: Jules Stacy",
       x = "ABV",
       y = "Percentage")

nbeer <- data.frame(1:2370)
nbeer$ABV <- mbeer$ABV
nbeer$State <- mbeer$State
nbeer <- nbeer[complete.cases(nbeer),]


mean(nbeer$ABV[which(!is.na(nbeer$ABV))])
median(nbeer$ABV[which(!is.na(nbeer$ABV))])
sd(nbeer$ABV[which(!is.na(nbeer$ABV))])
var(nbeer$ABV[which(!is.na(nbeer$ABV))])
summary(nbeer$ABV[which(!is.na(nbeer$ABV))])

abvmean = mean(nbeer$ABV[which(!is.na(nbeer$ABV))])
abvsd = sd(nbeer$ABV[which(!is.na(nbeer$ABV))])
abvmean - 2*abvsd
abvmean + 2*abvsd
```
The mean ABV for the dataset is 0.05987305
The median ABV for the dataset is 0.056
The standard deviation among ABV for the dataset is 0.01352549
The variance among ABV for the dataset is 0.0001829388

The quartile ranges are:
Min.      1st Qu.   3rd Qu.     Max.
0.00100   0.05000   0.06800     0.12800 

Based on these values, we can expect 95% of beers to fall between 0.03282208 and 0.08692402 ABV.

```{r Figure 4}
fig_4
```

Figure 4, above, shows a density curve for ABV. We can see that the distribution is approximately normal with right skew, with the mean centered at 0.0599. There appear to be additional popular ABV targets at approximately 0.06, 0.08, and 0.095, as evidenced by the spikes in the distribution at those numbers.

The code below calculates the linear model for ABV versus IBU, and generates Figure 5. The data does not include beers that have missing ABV or IBU values.
```{r Problem 7}
nbeer <- data.frame(1:2370)
nbeer$ABV <- mbeer$ABV
nbeer$IBU <- mbeer$IBU
nbeer$State <- mbeer$State
nbeer <- nbeer[complete.cases(nbeer),]

lm(nbeer$ABV ~ nbeer$IBU)
cor(nbeer$ABV, nbeer$IBU)

fig_5 = ggplot(mbeer) +
  geom_point(aes(ABV, IBU), color="deeppink3") +
  geom_smooth(aes(ABV, IBU), method="lm")+
    #labels
  labs(title = "Figure 5",
       subtitle = "ABV Versus IBU",
       caption = "Source: Breweries.csv \n Author: Jules Stacy",
       x = "ABV",
       y = "IBU")
```

```{r Figure 5}
fig_5
```

Figure 5, above, is a scatterplot of ABV versus IBU for the beers in the dataset that do not have missing values for either ABV or IBU. Visually, it appears that the data are related. According to analytical software there is a best-fit line with an equation of y= 0.0003506x + 0.0450713 and a correlation coefficient of 0.6690977. This means that 67% of the data is explained by the fitted line, and therefore ABV and IBU are moderately related.


The code below creates a dataset that will later be used to compare IPA's and Ales to see if there is a difference between the two with regard to their ABV and IBU. It also generates Figure 6.
```{r Problem 8.1}


mbeer$isipa <- as.numeric(str_detect(mbeer$Style, "IPA"))
mbeer$isale <- as.numeric(str_detect(mbeer$Style, "Ale"))
names(mbeer$isipa) <- "is_IPA"
names(mbeer$isale) <- "is_Ale"

ipa_g <- mbeer %>% filter(mbeer$isipa == 1)
ale_g <- mbeer %>% filter(mbeer$isale==1)

ipa_g$isipa <- "IPA"
ale_g$isipa <- "Ale"


ipa_g <- ipa_g[,c(4, 5, 11)]
ale_g <- ale_g[,c(4, 5, 11)]
beer_g <- merge(ipa_g, ale_g, all=TRUE)
beer_g <- beer_g[complete.cases(beer_g),]
beer_g$isipa <- as.factor(beer_g$isipa)


fig_6 <- ggplot(beer_g, aes(x=IBU, y=ABV)) +
  geom_point(aes(color=beer_g$isipa)) +
  labs(title = "Figure 6",
       subtitle = "IBU Versus ABV, Colored by Beer Type",
       caption = "Source: Breweries.csv \n Author: Jules Stacy",
       x = "IBU",
       y = "ABV")
```

```{r Figure 6}
fig_6
```

Figure 6, above, is a scatterplot of ABV versus IBU for IPA's and Ales. The two different types of beer are represented on the graph by different colors. We can immediately see that there is a difference between the two types of beer, where Ale tends to be less bitter and have a lower ABV, and IPA tends to be more bitter and have a higher ABV.

The code below finds the best k-value for running a k-nearest neighbors algorithm, where each point is compared with its nearest neighbors to determine a specific statistic (below, that statistic is IPA or Ale). The k-value determines how many nearby points are compared.

For the training-test sets, a 33% train 66% test split was used.
```{r Problem 8.2, eval = TRUE, echo = TRUE, message=FALSE, results = "hide"}
#beer_k is now a list of IPAs and Ales with ABV values, IBU values, and no NA values. Now it's time to develop a training and test set. Training set taken from cleaned data
mbeer$isipa <- as.numeric(str_detect(mbeer$Style, "IPA"))
mbeer$isale <- as.numeric(str_detect(mbeer$Style, "Ale"))

ipa_k <- mbeer %>% filter(mbeer$isipa == 1)
ale_k <- mbeer %>% filter(mbeer$isale==1)

ipa_k <- ipa_k[,c(4, 5, 11)]
ale_k <- ale_k[,c(4, 5, 11)]
beer_k <- merge(ipa_k, ale_k, all=TRUE)
beer_k <- beer_k[complete.cases(beer_k),]
beer_k$isipa <- as.factor(beer_k$isipa)

train <- beer_k[sample(nrow(beer_k), size=311),]
test <- setdiff(beer_k, train)

#--------------HYPERPARAMETER K TESTING--------------
#-----define parameters-----
kmax=25
loops=100
accs1 = data.frame(k = numeric(kmax), accuracy = numeric(kmax), accuracy2=numeric(kmax))
accs2 = data.frame(k = numeric(kmax), accuracy = numeric(kmax), accuracy2=numeric(kmax))

#-----define loop-----
#housed processes to speed compile time
#each loop processes train vs test and then icv
for(j in 1:loops){
  train <- beer_k[sample(nrow(beer_k), size=311),]
  test <- setdiff(beer_k, train)
for(i in 1:kmax)
{
  classifications1 = knn(train[,c(1,2)],test[,c(1,2)],train[,3], prob = TRUE, k = i)
  sur1 = table(test[,3],classifications1)
  CM1 = confusionMatrix(sur1)
  accs1$accuracy[i] = accs1$accuracy[i] + CM1$overall[1]
  accs1$k[i] = i
  
  classifications2 = knn.cv(beer_k[,c(1,2)], beer_k[,3], prob=TRUE, k=i)
  sur2 = table(beer_k[,3],classifications2)
  CM2 = confusionMatrix(sur2)
  accs2$accuracy[i] = accs2$accuracy[i] + CM2$overall[1]
  accs2$k[i] = i
  
  }
}

#finish the calculation of averages
accs1$accuracy <- accs1$accuracy/loops
accs2$accuracy <- accs2$accuracy/loops

#-----build plots-----
fig_7 <- ggplot(data=accs1, aes(x=k, y=accuracy)) +
  geom_point() +
  geom_text(aes(label=accs1$k), hjust=-.2, size=2.7)+
  labs(title = "Figure 7",
       subtitle = "Train and Test Hyperparameter K: 100 Iterations",
       caption = "Source: Breweries.csv \n Author: Jules Stacy",
       x = "Hyperparameter K",
       y = "Average Accuracy")

fig_8 <- ggplot(data=accs2, aes(x=k, y=accuracy)) +
  geom_point() +
  geom_text(aes(label=accs2$k), hjust=-.2, size=2.7)+
  labs(title = "Figure 8",
       subtitle = "Leave One Out Hyperparameter K: 100 Iterations",
       caption = "Source: Breweries.csv \n Author: Jules Stacy",
       x = "Hyperparameter K",
       y = "Average Accuracy")

#------------------------------------
#the best k for train-and-test is 19
#the best k for leave-one-out is 8
```
```{r Figure 7}
fig_7
```

Figure 7, above, is a graph of the average accuracy of 25 values of k looped 100 times using train-and-test. Based on the results of this graph I chose a k of 19 for my train-test analysis.

```{r Figure 8}
fig_8
```

Figure 8, above, is a graph of the average accuracy of 25 values of k looped 100 times using leave-one-out analysis. Based on the results of this graph I chose a k of 5 for my leave-one-out analysis.


The code below calculates the k-nearest neighbors test and train and leave one out accuracies for the dataset in order to determine computer accuracy at comparing IPA's and Ales.
```{r Problem 8.3}

#code for test and train

  classifications1 = knn(train[,c(1,2)],test[,c(1,2)],train[,3], prob = TRUE, k = 19)
  sur1 = table(test[,3],classifications1)
  CM1 = confusionMatrix(sur1)

#code for leave one out
  classifications2 = knn.cv(beer_k[,c(1,2)], beer_k[,3], prob=TRUE, k=5)
  sur2 = table(beer_k[,3],classifications2)
  CM2 = confusionMatrix(sur2)
```
  
```{r Table 6}
  CM1
```

Table 6, above (not shown), are the results of the train-and-test algorithm. Using this algorithm the computer was able to correctly type beers as either IPA or Ale 81.95% of the time based on ABV and IBU.

```{r Table 7}
  CM2
```

Table 7, above (not shown), shows the results of the leave-one-out algorithm. Using this method the computer was able to correctly type beers as either IPA or Ale 84.6% of the time based on ABV and IBU.


The code below looks at the most common words chosen when naming beers, and generates Figure 9.
```{r Problem 9.1, eval = TRUE, echo = FALSE, message=FALSE, results = "hide"}

invisible(mbeer <- mbeer[!duplicated(mbeer$Name),])

x=c()
for(i in 1:length(mbeer$Name)){
  invisible(x <- paste(x, mbeer[i,2]))
}

invisible(name_words <- str_split(x, "( )"))
invisible(gsub(" ", "", name_words))
invisible(names_table <- sort(table(name_words), decreasing=T))
invisible(names_table <- names_table[-58])
invisible(namewords_great10 <- names_table[1:76])
invisible(topwords <- as.data.frame(namewords_great10))

fig_9 <- ggplot2::ggplot(topwords, aes(x=name_words, y=Freq, fill=name_words)) + 
  geom_bar(width = 0.75,  stat = "identity", colour = "black", size = .3, las=0) +  
  theme(legend.position = "none", axis.text.x = element_text(angle = 90, hjust = 1)) + 
  labs(title = "Figure 9",
       subtitle = "Most Common Words in Beer Names (More Than 10 Appearances)",
       caption = "Source: Breweries.csv \n Author: Jules Stacy",
       x = "Words",
       y = "Count") +
  scale_y_log10()


```

```{r Figure 9}
fig_9
```

Figure 9, above, shows the most common words chosen when naming a beer. The most common naming convention for beers is to name it by the type of beer; this would be why "Ale" is the top word choice when naming a beer. Other notable inclusions are "of", which signifies that the beer has a complex name that may not attributed to its type, "the" versus "The", which specifies that some beers are named starting with the word "The" and therefore have a more title-esque name whereas some beers are named with "the" in the middle of the beer, again hinting at names not related to beer type, and various years that may have been particularly good hops growing seasons or experimental years; particularly 2012. Additionally there are words that suggest that aged beers are popular, such as "Barrel" and "Old."


The code below conducts an analysis of variance on the dataset in order to see if there are any significant differences in ABV or IBU from state to state.
```{r Problem 9.2, eval = TRUE, echo = TRUE, message=FALSE, results = "hide"}
attach(nbeer)
invisible(ABVfit <- aov(ABV ~ State))
invisible(TukeyHSD(ABVfit))

invisible(ABVfit <- aov(ABV ~ State))
abv_tukey = TukeyHSD(ABVfit)
invisible(abv_tukey <- as.data.frame(abv_tukey$State))
names(abv_tukey) = c( "diff", "lwr", "upr", "p_adj")
abv_tukey$States <- rownames(abv_tukey)

IBUfit <- aov(IBU ~ State)
ibu_tukey = TukeyHSD(IBUfit)
ibu_tukey <- as.data.frame(ibu_tukey$State)
names(ibu_tukey) = c( "diff", "lwr", "upr", "p_adj")
ibu_tukey$States <- rownames(ibu_tukey)
```


```{r Table 8}

#Analysis Output

abv_tukey %>% filter(p_adj < 0.05)



```


Table 8, above (not shown), shows the states between which there is a statistically significant difference in the mean alcohol content of their beer. Based on the results of this table there could be a potential market for stronger Colorado  beers in both Missouri and Wisconsin.



```{r Table 9}
ibu_tukey %>% filter(p_adj < 0.05)

```

Table 9, above (not shown), shows the states between which there is a statistically significant difference in the mean IBU of their beer. The resuls of this table show that Wisconsin breweries brew less bitter beer than Oregon, California, Colorado, and Minnesota. If Budweiser were to open a brewery in Wisconsin, I would advise brewing low-IBU beers.



If interested, here are some further analysis that can be run on this dataset:
- ABV vs. IBU comparisons for all individual styles of beer
- Most popular style of beer to produce
- Most popular style by state
- Marketing tactics based on style of beer